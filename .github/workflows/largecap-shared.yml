name: LargeCap (shared)

on:
  workflow_call:
    inputs:
      send_discord:
        type: boolean
        default: true
      python-version:
        type: string
        default: '3.11'
      trails_keep_hours:         # daily だけ >0 を渡す
        type: number
        default: 0
    secrets:
      DISCORD_WEBHOOK_URL:
        required: false
      DISCORD_WEBHOOK:           # 旧名も許容
        required: false

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    permissions:
      contents: write
    env:
      MPLBACKEND: Agg
      # if: から参照できるよう job 環境にまとめる
      WEBHOOK: ${{ secrets.DISCORD_WEBHOOK_URL || secrets.DISCORD_WEBHOOK }}

    steps:
      # 1) リポジトリ取得
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Sync repo (pull latest)
        run: |
          git config --global pull.rebase true
          git pull --rebase --autostash || true

      # 2) Python 準備
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ inputs.python-version }}
          cache: pip

      # 3) 依存
      - name: Install deps
        shell: bash
        run: |
          set -euo pipefail
          python -m pip install -U pip
          pip install -r requirements.txt || pip install -U requests pyyaml pandas matplotlib

      # 4) effective を作成（部品）
      - name: Build effective configs (inject excludes)
        id: eff
        uses: ./.github/actions/build-effectives
        with:
          env-file: .github/workflows/largecap-watch.env
          configs: |
            config_largecap.yaml
            config_largecap_btc.yaml
            config_largecap_compare.yaml

      - name: Sanity check excludes (15m)
        shell: bash
        run: |
          python - <<'PY'
          import yaml, pathlib
          for p in (
              "config_largecap.effective.yaml",
              "config_largecap_btc.effective.yaml",
              "config_largecap_compare.effective.yaml",
          ):
              path = pathlib.Path(p)
              if not path.exists():
                  print(f"[CFG] skip {p} (not found)")
                  continue
              y = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
              ex = y.get("exclude_ids") or []
              print(f"[CFG] {p}: exclude_ids={len(ex)}")
          PY

      # 5) 強弱（USD/BTC）
      - name: Run USD strength (15m)
        shell: bash
        run: python largecap_strength.py --config config_largecap.effective.yaml

      - name: Pause to avoid 429
        shell: bash
        run: sleep 8

      - name: Run BTC strength (15m)
        shell: bash
        run: python largecap_strength_btc.py --config config_largecap_btc.effective.yaml

      # 6) 比較（--trails-* は渡さない）
      - name: Run compare
        shell: bash
        run: |
          set -euo pipefail
          python compare_strength.py --config config_largecap_compare.effective.yaml

      # (daily only) 履歴ファイルが無ければ正しいヘッダーで初期化
      - name: Ensure trails history exists (daily)
        if: ${{ fromJSON(inputs.trails_keep_hours) > 0 }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data
          if [[ ! -f data/trails_db.csv ]]; then
            # ← plot_score_trails.py が参照する列名に合わせる
            echo "timestamp,symbol,usd_score,btc_score" > data/trails_db.csv
            echo "[init] created data/trails_db.csv (empty with header)"
          fi
          head -n 2 data/trails_db.csv || true
          
      # (daily only) 履歴CSVが空なら、現在のUSD/BTCスナップショットで種付け
      - name: Seed trails history from current snapshots (first run only)
        if: ${{ fromJSON(inputs.trails_keep_hours) > 0 }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data
          [[ -f data/trails_db.csv ]] || echo "timestamp,symbol,usd_score,btc_score" > data/trails_db.csv
      
          # 行数が1（=ヘッダのみ）なら種付け
          if [[ $(wc -l < data/trails_db.csv) -le 1 ]]; then
            cat >/tmp/seed_trails.py <<'PY'
          import pandas as pd, pathlib, datetime as dt
          
          def pick_score_col(df):
              for c in ['score','usd_score','btc_score','value','strength']:
                  if c in df.columns: return c
              num = df.select_dtypes('number').columns.tolist()
              return num[-1] if num else None
          
          p_usd = pathlib.Path('data/largecap_strength.csv')
          p_btc = pathlib.Path('data/largecap_strength_btc.csv')
          if not p_usd.exists() or not p_btc.exists():
              raise SystemExit("USD/BTC snapshot csv missing")
          
          dfu = pd.read_csv(p_usd)
          dfb = pd.read_csv(p_btc)
          
          cu = pick_score_col(dfu)
          cb = pick_score_col(dfb)
          if not cu or not cb:
              raise SystemExit(f"score columns not found (usd={cu}, btc={cb})")
          
          a = dfu[['symbol', cu]].rename(columns={cu:'usd_score'})
          b = dfb[['symbol', cb]].rename(columns={cb:'btc_score'})
          m = a.merge(b, on='symbol', how='outer')
          
          ts = dt.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'
          m.insert(0, 'timestamp', ts)
          
          m[['timestamp','symbol','usd_score','btc_score']].to_csv(
              'data/trails_db.csv', mode='a', header=False, index=False
          )
          print(f"[seed] appended {len(m)} rows into data/trails_db.csv at {ts}")
          PY
          python /tmp/seed_trails.py
          else
            echo "[seed] trails_db.csv already has rows, skip"
          fi
      
          head -n 3 data/trails_db.csv || true

      # quiet legacy JSON warning (optional)
      - name: Quiet legacy JSON history warning
        if: ${{ fromJSON(inputs.trails_keep_hours) > 0 }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data
          [[ -f data/trails_db.json ]] || echo '{"usd":[],"btc":[]}' > data/trails_db.json
      
      # (daily only) trails_db.csv を検査・修復（ヘッダ/改行/区切り/BOM）
      - name: Repair/seed trails history if needed (daily)
        if: ${{ fromJSON(inputs.trails_keep_hours) > 0 }}
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p data
          f="data/trails_db.csv"
      
          # 1) 無ければ正しいヘッダで新規作成
          if [[ ! -f "$f" ]]; then
            echo "timestamp,symbol,usd_score,btc_score" > "$f"
            echo "[repair] init header -> $f"
          fi
      
          # 2) 改行コードをLF化（CRLF混入対策）
          sed -i 's/\r$//' "$f"
      
          # 3) 先頭にBOMが付いていたら除去
          # （BOMが付くとヘッダが 'ï»¿timestamp' になり、pandasが 'timestamp' を見失う）
          if head -c3 "$f" | grep -q $'^\xEF\xBB\xBF'; then
            tail -c +4 "$f" > /tmp/_clean && mv /tmp/_clean "$f"
            echo "[repair] removed UTF-8 BOM"
          fi
      
          # 4) 区切りがカンマか確認（;やTABなら置換）
          head -n1 "$f" | grep -q ',' || {
            if head -n1 "$f" | grep -q ';'; then
              sed -i '1s/;/,/g' "$f"
              sed -i '2,$s/;/,/g' "$f"
              echo "[repair] replaced ; -> ,"
            elif head -n1 "$f" | grep -q $'\t'; then
              awk -v OFS=',' 'BEGIN{FS="\t"} {print $0}' "$f" > /tmp/_csv && mv /tmp/_csv "$f"
              echo "[repair] replaced TAB -> ,"
            fi
          }
      
          # 5) ヘッダ検査：timestamp が無ければヘッダを正規化
          h="$(head -n1 "$f")"
          if ! echo "$h" | grep -q '^timestamp,'; then
            echo "[repair] normalize header"
            tail -n +2 "$f" > /tmp/_rest || true
            printf "timestamp,symbol,usd_score,btc_score\n" > "$f"
            cat /tmp/_rest >> "$f" || true
          fi
      
          # 6) 行が1（ヘッダのみ）なら現在のスナップショットで種付け
          if [[ $(wc -l < "$f") -le 1 ]]; then
            cat >/tmp/seed_trails.py <<'PY'
            import pandas as pd, pathlib, datetime as dt
            def pick_score_col(df):
                for c in ['score','usd_score','btc_score','value','strength']:
                    if c in df.columns: return c
                num = df.select_dtypes('number').columns.tolist()
                return num[-1] if num else None
                p_usd = pathlib.Path('data/largecap_strength.csv')
                p_btc = pathlib.Path('data/largecap_strength_btc.csv')
                if (not p_usd.exists()) or (not p_btc.exists()):
                    raise SystemExit("snapshot csv missing")
                dfu = pd.read_csv(p_usd)
                dfb = pd.read_csv(p_btc)
                cu = pick_score_col(dfu); cb = pick_score_col(dfb)
                a = dfu[['symbol', cu]].rename(columns={cu:'usd_score'})
                b = dfb[['symbol', cb]].rename(columns={cb:'btc_score'})
                m = a.merge(b, on='symbol', how='outer')
                ts = dt.datetime.utcnow().replace(microsecond=0).isoformat() + 'Z'
                m.insert(0, 'timestamp', ts)
                m[['timestamp','symbol','usd_score','btc_score']].to_csv(
                    'data/trails_db.csv', mode='a', header=False, index=False
                )
                print(f"[seed] appended {len(m)} rows into data/trails_db.csv at {ts}")
                PY
                python /tmp/seed_trails.py
            fi     
            echo "== head trails_db.csv =="
            head -n 3 "$f" | cat -A

      # 7) daily のときだけ長期トレイルを更新
      - name: Update trails (long-range; daily only)
        if: ${{ fromJSON(inputs.trails_keep_hours) > 0 }}
        shell: bash
        run: |
          set -euo pipefail
          TRAILS_KEEP_HOURS='${{ toJSON(inputs.trails_keep_hours) }}'

          python plot_score_trails.py \
            --metric usd \
            --hist data/trails_db.csv \
            --hours "$TRAILS_KEEP_HOURS"
      
          python plot_score_trails.py \
            --metric btc \
            --hist data/trails_db.csv \
            --hours "$TRAILS_KEEP_HOURS"
      
          ls -l --time-style=long-iso data/score_trails_*.png || true

      
          # USD 側のトレイルを更新
          python plot_score_trails.py \
            --metric usd \
            --hist data/trails_db.csv \
            --hours "$TRAILS_KEEP_HOURS"
      
          # BTC 側のトレイルを更新
          python plot_score_trails.py \
            --metric btc \
            --hist data/trails_db.csv \
            --hours "$TRAILS_KEEP_HOURS"
      
          # 生成されたファイル確認（ログ用）
          ls -l --time-style=long-iso data/score_trails_*.png || true

      # 8) 迷子の生成物を data/ に集約（保険）
      - name: Normalize artifacts into data/
        shell: bash
        run: |
          set -euo pipefail
          shopt -s nullglob
          mkdir -p data
          for f in largecap_*.png largecap_*.csv score_trails_*.png score_trails_*.csv; do
            [[ -e "$f" ]] && mv -f "$f" data/
          done

      # 生成直後チェック（mtime/ハッシュ）
      - name: Verify artifacts freshness & diff
        shell: bash
        run: |
          set -euo pipefail
          files=(data/largecap_usd_vs_btc.png data/largecap_strength.png data/largecap_strength_btc.png data/score_trails_usd.png data/score_trails_btc.png data/score_trails_usdxbtc.png)
          echo "== mtimes & size =="
          ls -l --time-style=long-iso "${files[@]}"
          echo "== current sha256 =="
          sha256sum "${files[@]}" || true
          echo "== previous commit sha256 =="
          for f in "${files[@]}"; do
            if git show "HEAD:$f" >/tmp/prev 2>/dev/null; then
              echo "-- $f"; sha256sum /tmp/prev
            else
              echo "-- $f : (no previous)"
            fi
          done


      # 9) Discord 送信（data/ 固定 + 鮮度ガード）
      - name: Send charts to Discord
        if: ${{ inputs.send_discord && env.WEBHOOK != '' }}
        shell: bash
        run: |
          set -euo pipefail
          WEBHOOK="$(printf '%s' "$WEBHOOK" | tr -d '\r\n' | sed -e 's/^ *//' -e 's/ *$//')"

          files=( 
            data/largecap_usd_vs_btc.png
            data/score_trails_usd.png
            data/score_trails_btc.png
            data/largecap_strength.png
            data/largecap_strength_btc.png
            data/score_trails_usdxbtc.png
          )

          now=$(date +%s); max_age=$((60*60))
          for f in "${files[@]}"; do
            [[ -f "$f" ]] || { echo "missing $f"; exit 1; }
            m=$(stat -c %Y "$f"); (( now-m <= max_age )) || { echo "stale $f"; exit 1; }
          done

          payload="$(jq -n --arg content "LargeCap 15m — $(date -u +'%Y-%m-%d %H:%M UTC')" '{content:$content}')"

          curl --fail-with-body -sS \
            -F "payload_json=${payload}" \
            -F "file1=@${files[0]};type=image/png" \
            -F "file2=@${files[1]};type=image/png" \
            -F "file3=@${files[2]};type=image/png" \
            -F "file4=@${files[3]};type=image/png" \
            -F "file5=@${files[4]};type=image/png" \
            -F "file6=@${files[5]};type=image/png" \
            "$WEBHOOK"

      # 10) 生成物コミット
      - name: Commit & push artifacts
        shell: bash
        run: |
          set -euo pipefail
          git config user.name  github-actions
          git config user.email github-actions@github.com
          git add -A
          git diff --cached --quiet && { echo "Nothing to commit"; exit 0; }
          git commit -m "Update trails $(date -u +'%Y-%m-%dT%H:%MZ')"
          git pull --rebase --autostash
          git push
